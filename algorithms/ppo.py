# do a policy based RL (just one network) with the ppo loss function
# advantages of PPO are found in a discrete actions and multi-process style; offers fast convergence